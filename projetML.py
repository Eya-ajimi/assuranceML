# -*- coding: utf-8 -*-
"""Copie de mini_projet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z876EI5PlS_dDC1uyDKoHmL56X50fxcd
"""

#Importation des bibliothèques
import pandas as pd
import seaborn as sns
from sklearn.compose import ColumnTransformer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

#Partie 1: Exploration des données

# Supposons que le fichier s'appelle 'dataAssurance.csv'
df_assurance = pd.read_csv('dataAssurance.csv')

df_assurance.head()

#Structure du dataset
df_assurance.columns

#Taille du dataset
df_assurance.shape

#Partie 1: Nettoyage de données

#Gestion des doublons
#1- Détection des doublons
print("Nombre de doublons:", df_assurance.duplicated().sum())
#2- Supprimer les doublons
df_assurance.drop_duplicates(inplace=True)
#3-Vérification de la suppression des doublons
print("Nombre de doublons après suppression:", df_assurance.duplicated().sum())

#Vérification de l'existence des valeurs aberrantes
#Créer des boxplots pour chaque colonne
# Vérification de l'existence des valeurs aberrantes
# Créer des boxplots uniquement pour les colonnes numériques
numeric_columns = df_assurance.select_dtypes(include=[np.number]).columns

print("Colonnes numériques détectées:", list(numeric_columns))

for column in numeric_columns:
    if column != 'charges':  # Exclure la cible si nécessaire
        plt.figure(figsize=(8, 4))
        sns.boxplot(x=df_assurance[column])
        plt.title(f'Boxplot de {column}')
        plt.xlabel(column)
        plt.show()

# Calcul des statistiques pour BMI
Q1 = df_assurance['bmi'].quantile(0.25)
Q3 = df_assurance['bmi'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

print(f"Q1 (25ème percentile): {Q1:.2f}")
print(f"Q3 (75ème percentile): {Q3:.2f}")
print(f"IQR: {IQR:.2f}")
print(f"Borne inférieure: {lower_bound:.2f}")
print(f"Borne supérieure: {upper_bound:.2f}")

# Identifier les outliers
bmi_outliers = df_assurance[(df_assurance['bmi'] < lower_bound) | (df_assurance['bmi'] > upper_bound)]
print(f"\nNombre d'outliers dans BMI: {len(bmi_outliers)}")
print("\nValeurs outliers:")
print(bmi_outliers['bmi'].sort_values())

#Plage d'outliers : [47.41,53.13]
#On conserve les outliers car elles correspondent à des cas d'obésité sévère, qui sont médicalement plausibles.

#Gestion des valeurs manquantes
#1-Détection des valeurs manquantes
df_assurance.isnull().sum()

#2-Imputation des valeurs manquantes
# 1. age - Imputation par la médiane
df_assurance['age'] = df_assurance['age'].fillna(df_assurance['age'].median())

# 2. sex - Imputation par le mode
df_assurance['sex'] = df_assurance['sex'].fillna(df_assurance['sex'].mode()[0])

# 3. bmi - Imputation par la médiane (robuste aux outliers)
df_assurance['bmi'] = df_assurance['bmi'].fillna(df_assurance['bmi'].median())

# 4. children - Imputation par le mode
df_assurance['children'] = df_assurance['children'].fillna(df_assurance['children'].mode()[0])

# 5. smoker - Imputation par le mode
df_assurance['smoker'] = df_assurance['smoker'].fillna(df_assurance['smoker'].mode()[0])

# 6. region - Imputation par le mode
df_assurance['region'] = df_assurance['region'].fillna(df_assurance['region'].mode()[0])

df_assurance.isnull().sum()

#Suppression des lignes contenant la valeur NULL pour la cible
df_assurance = df_assurance.dropna(subset=['charges'])
df_assurance.isnull().sum()

df_assurance.info()

#Partie 2: Transformation des données

#Séparation des variables
X = df_assurance.drop("charges", axis=1)
y = df_assurance["charges"]

from sklearn.preprocessing import OneHotEncoder, MinMaxScaler
# Colonnes par type
categorical_cols = ['sex', 'smoker', 'region']
numeric_cols = ['age', 'bmi', 'children']

# 1. Encodage One-Hot des variables catégorielles
encoder = OneHotEncoder(sparse_output=False)
one_hot_encoded = encoder.fit_transform(X[categorical_cols])

# Création du DataFrame des variables encodées
encoded_df = pd.DataFrame(one_hot_encoded,
                         columns=encoder.get_feature_names_out(categorical_cols))

# 2. Normalisation des variables numériques
scaler = MinMaxScaler()
scaled_numeric = scaler.fit_transform(X[numeric_cols])

# Création du DataFrame des variables normalisées
scaled_df = pd.DataFrame(scaled_numeric, columns=numeric_cols)

# 3. Combinaison des données transformées
X_transformed = pd.concat([scaled_df, encoded_df], axis=1)

# Résultat final
print(X_transformed.head())

#Importance des features sur les charges
from sklearn.ensemble import RandomForestRegressor


# 1. Créer le modèle Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42)

# 2. Entraîner le modèle sur les features transformées et la target
rf.fit(X_transformed, y)

# 3. Récupérer l'importance des features
feature_importances = pd.Series(rf.feature_importances_, index=X_transformed.columns)

# 4. Trier les features par importance décroissante
feature_importances = feature_importances.sort_values(ascending=False)

# 5. Afficher les résultats
print(feature_importances)

"""# Objectif DS: Segmentation des assurés"""

# Modèle 1: KMeans

"""# Modèle 1: KMeans"""

# === Feature Engineering pour le reporting ===
df_assurance['bmi_category'] = pd.cut(df_assurance['bmi'],
                                     bins=[0, 18.5, 25, 30, 35, 100],
                                     labels=['Sous-poids', 'Normal', 'Surpoids', 'Obésité I', 'Obésité II'])
df_assurance['age_group'] = pd.cut(df_assurance['age'],
                                  bins=[0, 30, 45, 60, 100],
                                  labels=['Jeune', 'Adulte', 'Senior', 'Âgé'])
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import numpy as np
# === Méthode du coude + Score de silhouette ===
inertia = []
silhouette_scores = []
K_range = range(2, 6)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_transformed)

    inertia.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_transformed, cluster_labels))

# Visualisation
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

ax1.plot(K_range, inertia, marker='o')
ax1.set_xlabel('Nombre de clusters K')
ax1.set_ylabel('Inertia')
ax1.set_title('Méthode du coude')

ax2.plot(K_range, silhouette_scores, marker='o', color='red')
ax2.set_xlabel('Nombre de clusters K')
ax2.set_ylabel('Score de Silhouette')
ax2.set_title('Score de Silhouette')

plt.tight_layout()
plt.show()

optimal_k = K_range[np.argmax(silhouette_scores)]
print(f"K optimal (silhouette): {optimal_k}")
print(f"Score de silhouette max: {max(silhouette_scores):.3f}")

kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
clusters = kmeans_final.fit_predict(X_transformed)
df_assurance['cluster'] = clusters

# Noms commerciaux adaptés à k=3
cluster_names_final = {
    0: "Fumeurs Actifs - Haut Risque",
    1: "Non-Fumeurs - Surpoids/Obésité Modérée",
    2: "Non-Fumeurs - Poids Normal/Surpoids Léger"
}
df_assurance['nom_cluster'] = df_assurance['cluster'].map(cluster_names_final)
cluster_packs_final = {}

# Profiling et reporting K-Means
for cluster_id in range(optimal_k):
    data = df_assurance[df_assurance['cluster']==cluster_id]
    name = cluster_names_final[cluster_id]
    smoker_pct = (data['smoker']=='yes').mean()*100
    avg_bmi = data['bmi'].mean()
    avg_charges = data['charges'].mean()

    if smoker_pct > 40:
        risk = "TRÈS ÉLEVÉ"; pack = "Premium Plus"
    elif smoker_pct > 10 or avg_bmi > 32:
        risk = "ÉLEVÉ"; pack = "Premium"
    elif avg_bmi > 28:
        risk = "MODÉRÉ"; pack = "Standard Plus"
    else:
        risk = "FAIBLE"; pack = "Standard"
       # Sauvegarde
    cluster_packs_final[cluster_id] = pack

    print(f"\nCluster {cluster_id} ({name}) - {len(data)} clients")
    print(f"  Âge moyen: {data['age'].mean():.1f}, BMI moyen: {avg_bmi:.1f}, Enfants moyens: {data['children'].mean():.1f}")
    print(f"  % Fumeurs: {smoker_pct:.1f}%, Région principale: {data['region'].mode()[0]}")
    print(f"  Charges moyennes: ${avg_charges:,.2f} (min {data['charges'].min():.0f}, max {data['charges'].max():.0f})")
    print(f"  Niveau de risque: {risk}, Pack: {pack}")

# Synthèse globale K-Means
cluster_summary = df_assurance.groupby('cluster').agg({
    'age':'mean','bmi':'mean','children':'mean',
    'smoker': lambda x: (x=='yes').mean()*100,
    'charges':['mean','std','count']
}).round(2)
cluster_summary.columns = ['age_moyen','bmi_moyen','enfants_moyens','pourcent_fumeurs','charges_moyennes','ecart_type_charges','effectif']
cluster_summary['nom_cluster'] = cluster_summary.index.map(cluster_names_final)
print("\nSYNTHÈSE GLOBALE KMEANS")
print(cluster_summary)

# Palette de couleurs
colors = plt.cm.Set1.colors

# Cluster IDs et mapping couleur
cluster_ids = sorted(df_assurance['cluster'].unique())
color_map = {i: colors[i % len(colors)] for i in cluster_ids}

# Création des sous-graphes
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# === 1. Charges vs Âge par cluster ===
for cluster_id in cluster_ids:
    cluster_data = df_assurance[df_assurance['cluster'] == cluster_id]
    axes[0, 0].scatter(
        cluster_data['age'], cluster_data['charges'],
        color=color_map[cluster_id],
        label=cluster_names_final[cluster_id],
        alpha=0.7
    )
axes[0, 0].set_xlabel('Âge', fontsize=12)
axes[0, 0].set_ylabel('Charges ($)', fontsize=12)
axes[0, 0].set_title('Charges vs Âge par Cluster (KMeans)', fontsize=14)
axes[0, 0].legend(loc='best', fontsize=10)
axes[0, 0].grid(True, alpha=0.3)

# === 2. Charges vs BMI par cluster ===
for cluster_id in cluster_ids:
    cluster_data = df_assurance[df_assurance['cluster'] == cluster_id]
    axes[0, 1].scatter(
        cluster_data['bmi'], cluster_data['charges'],
        color=color_map[cluster_id],
        label=cluster_names_final[cluster_id],
        alpha=0.7
    )
axes[0, 1].set_xlabel('BMI', fontsize=12)
axes[0, 1].set_ylabel('Charges ($)', fontsize=12)
axes[0, 1].set_title('Charges vs BMI par Cluster (KMeans)', fontsize=14)
axes[0, 1].legend(loc='best', fontsize=10)
axes[0, 1].grid(True, alpha=0.3)

# === 3. Impact Fumeur sur les charges ===
smoker_charges = df_assurance.groupby(['cluster', 'smoker'])['charges'].mean().unstack()
smoker_charges = smoker_charges.rename(index=cluster_names_final)
smoker_charges.plot(
    kind='bar', ax=axes[1, 0],
    color=['#66c2a5', '#fc8d62'],
    width=0.7
)
axes[1, 0].set_title('Impact Fumeur sur Charges par Cluster (KMeans)', fontsize=14)
axes[1, 0].set_ylabel('Charges Moyennes ($)', fontsize=12)
axes[1, 0].tick_params(axis='x', rotation=45)
axes[1, 0].legend(title='Fumeur', fontsize=10)
axes[1, 0].grid(True, alpha=0.3)

# === 4. Charges moyennes par cluster avec écart-type ===
charges_stats = df_assurance.groupby('cluster')['charges'].agg(['mean', 'std'])
charges_stats.index = charges_stats.index.map(cluster_names_final)
axes[1, 1].bar(
    charges_stats.index,
    charges_stats['mean'],
    yerr=charges_stats['std'],
    capsize=5,
    color=[color_map[i] for i in cluster_ids],
    alpha=0.8
)
axes[1, 1].set_title('Charges Moyennes ± Écart-Type par Cluster (KMeans)', fontsize=14)
axes[1, 1].set_ylabel('Charges ($)', fontsize=12)
axes[1, 1].tick_params(axis='x', rotation=45)
axes[1, 1].grid(True, axis='y', alpha=0.3)

plt.tight_layout()
plt.show()

#Modèle 2:AgglomerativeClustering

"""# Modèle 2: AgglomerativeClustering"""

from sklearn.cluster import AgglomerativeClustering

agglo = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')
clusters_hier = agglo.fit_predict(X_transformed)
df_assurance['cluster_hier'] = clusters_hier

# Noms commerciaux adaptés à k=3
cluster_names_hier = {
    0: "Non-Fumeurs - Poids Normal/Surpoids Léger",
    1: "Fumeurs Intensifs - Haut Risque",
    2: "Non-Fumeurs - Surpoids/Obésité Modérée"
}
df_assurance['nom_cluster_hier'] = df_assurance['cluster_hier'].map(cluster_names_hier)
cluster_packs_hier = {}

# Profiling et reporting Agglomerative
for cluster_id in range(optimal_k):
    data = df_assurance[df_assurance['cluster_hier']==cluster_id]
    name = cluster_names_hier[cluster_id]
    smoker_pct = (data['smoker']=='yes').mean()*100
    avg_bmi = data['bmi'].mean()
    avg_charges = data['charges'].mean()

    if smoker_pct > 40:
        risk = "TRÈS ÉLEVÉ"; pack = "Premium Plus"
    elif smoker_pct > 10 or avg_bmi > 32:
        risk = "ÉLEVÉ"; pack = "Premium"
    elif avg_bmi > 28:
        risk = "MODÉRÉ"; pack = "Standard Plus"
    else:
        risk = "FAIBLE"; pack = "Standard"
    cluster_packs_hier[cluster_id] = pack

    print(f"\nCluster {cluster_id} ({name}) - {len(data)} clients")
    print(f"  Âge moyen: {data['age'].mean():.1f}, BMI moyen: {avg_bmi:.1f}, Enfants moyens: {data['children'].mean():.1f}")
    print(f"  % Fumeurs: {smoker_pct:.1f}%, Région principale: {data['region'].mode()[0]}")
    print(f"  Charges moyennes: ${avg_charges:,.2f} (min {data['charges'].min():.0f}, max {data['charges'].max():.0f})")
    print(f"  Niveau de risque: {risk}, Pack: {pack}")

# Synthèse globale Agglomerative
cluster_summary_hier = df_assurance.groupby('cluster_hier').agg({
    'age':'mean','bmi':'mean','children':'mean',
    'smoker': lambda x: (x=='yes').mean()*100,
    'charges':['mean','std','count']
}).round(2)
cluster_summary_hier.columns = ['age_moyen','bmi_moyen','enfants_moyens','pourcent_fumeurs','charges_moyennes','ecart_type_charges','effectif']
cluster_summary_hier['nom_cluster'] = cluster_summary_hier.index.map(cluster_names_hier)
print("\nSYNTHÈSE GLOBALE AGGLOMERATIVE")
print(cluster_summary_hier)

# Palette de couleurs
colors = plt.cm.Set1.colors
cluster_ids = sorted(df_assurance['cluster_hier'].unique())
color_map = {i: colors[i % len(colors)] for i in cluster_ids}

# Création des sous-graphes
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# === 1. Charges vs Âge ===
for cluster_id in cluster_ids:
    cluster_data = df_assurance[df_assurance['cluster_hier'] == cluster_id]
    axes[0, 0].scatter(
        cluster_data['age'], cluster_data['charges'],
        color=color_map[cluster_id],
        label=cluster_names_hier[cluster_id],
        alpha=0.7
    )
axes[0, 0].set_xlabel('Âge', fontsize=12)
axes[0, 0].set_ylabel('Charges ($)', fontsize=12)
axes[0, 0].set_title('Charges vs Âge par Cluster (Hiérarchique)', fontsize=14)
axes[0, 0].legend(loc='best', fontsize=10)
axes[0, 0].grid(True, alpha=0.3)

# === 2. Charges vs BMI ===
for cluster_id in cluster_ids:
    cluster_data = df_assurance[df_assurance['cluster_hier'] == cluster_id]
    axes[0, 1].scatter(
        cluster_data['bmi'], cluster_data['charges'],
        color=color_map[cluster_id],
        label=cluster_names_hier[cluster_id],
        alpha=0.7
    )
axes[0, 1].set_xlabel('BMI', fontsize=12)
axes[0, 1].set_ylabel('Charges ($)', fontsize=12)
axes[0, 1].set_title('Charges vs BMI par Cluster (Hiérarchique)', fontsize=14)
axes[0, 1].legend(loc='best', fontsize=10)
axes[0, 1].grid(True, alpha=0.3)

# === 3. Impact Fumeur sur les charges ===
smoker_charges = df_assurance.groupby(['cluster_hier', 'smoker'])['charges'].mean().unstack()
smoker_charges = smoker_charges.rename(index=cluster_names_hier)
smoker_charges.plot(
    kind='bar', ax=axes[1, 0],
    color=['#66c2a5', '#fc8d62'],
    width=0.7
)
axes[1, 0].set_title('Impact Fumeur sur Charges par Cluster', fontsize=14)
axes[1, 0].set_ylabel('Charges Moyennes ($)', fontsize=12)
axes[1, 0].tick_params(axis='x', rotation=45)
axes[1, 0].legend(title='Fumeur', fontsize=10)

# === 4. Charges moyennes ± écart-type par cluster ===
charges_stats = df_assurance.groupby('cluster_hier')['charges'].agg(['mean', 'std']).rename(index=cluster_names_hier)
cluster_order = charges_stats.index.tolist()
colors_bars = [color_map[i] for i in cluster_ids]  # Associer couleur à chaque cluster

axes[1, 1].bar(
    charges_stats.index,
    charges_stats['mean'],
    yerr=charges_stats['std'],
    capsize=5,
    color=colors_bars,
    alpha=0.8
)
axes[1, 1].set_title('Charges Moyennes ± Écart-Type par Cluster', fontsize=14)
axes[1, 1].set_ylabel('Charges ($)', fontsize=12)
axes[1, 1].tick_params(axis='x', rotation=45)
axes[1, 1].grid(True, axis='y', alpha=0.3)

plt.tight_layout()
plt.show()

from sklearn.metrics import adjusted_rand_score

# Comparer la stabilité entre les deux méthodes
stability_score = adjusted_rand_score(clusters, clusters_hier)
print(f"Accord entre méthodes: {stability_score:.3f}")

from sklearn.metrics import silhouette_score

def comparer_silhouette(X, labels_kmeans, labels_agglom):
    """
    Compare le Silhouette Score entre KMeans et Agglomerative Clustering.

    Paramètres:
        X : ndarray ou DataFrame
            Données transformées (features utilisées pour le clustering)
        labels_kmeans : array
            Labels prédits par KMeans
        labels_agglom : array
            Labels prédits par Agglomerative Clustering

    Retourne:
        meilleur_modele : str
            "KMeans" ou "Agglomerative Clustering"
    """

    # Calcul des scores
    silhouette_kmeans = silhouette_score(X, labels_kmeans)
    silhouette_agglo = silhouette_score(X, labels_agglom)

    print(f"\n📊 Silhouette KMeans: {silhouette_kmeans:.3f}")
    print(f"📊 Silhouette Agglomerative: {silhouette_agglo:.3f}")

    # Sélection du meilleur modèle
    if silhouette_kmeans > silhouette_agglo:
        meilleur_modele = "KMeans"
        print("🎯 CONCLUSION : KMeans est le meilleur modèle (Silhouette plus élevé)")
    else:
        meilleur_modele = "Agglomerative Clustering"
        print("🎯 CONCLUSION : Agglomerative Clustering est le meilleur modèle (Silhouette plus élevé)")

    return meilleur_modele
# === SELECTION MODELE ===
meilleur_modele = comparer_silhouette(X_transformed, df_assurance['cluster'], df_assurance['cluster_hier'])

def predict_cluster(X_client_transformed):
    """Prédit le cluster pour un nouveau client"""

    if meilleur_modele == "KMeans":
        cluster_id = kmeans_final.predict(X_client_transformed)[0]
        nom_cluster = cluster_names_kmeans[cluster_id] # type: ignore
    else:
        # Pour Agglomerative, on doit prédire manuellement
        from sklearn.neighbors import NearestNeighbors
        # Trouve le cluster le plus proche parmi les données d'entraînement
        nn = NearestNeighbors(n_neighbors=1)
        nn.fit(X_transformed)
        _, indices = nn.kneighbors(X_client_transformed)
        cluster_id = df_assurance.iloc[indices[0][0]]['cluster_hier']
        nom_cluster = cluster_names_hier[cluster_id]

    return cluster_id, nom_cluster, meilleur_modele

def preprocess_client_data(df_client):
    """
    Transforme les nouvelles données comme X_transformed :
    - Normalisation des colonnes numériques
    - One-Hot encoding des colonnes catégorielles
    """
    # Colonnes
    numeric_cols = ['age','bmi','children']
    categorical_cols = ['sex','smoker','region']

    # 1. Encodage One-Hot
    one_hot = encoder.transform(df_client[categorical_cols])
    one_hot_df = pd.DataFrame(one_hot, columns=encoder.get_feature_names_out(categorical_cols))

    # 2. Normalisation
    scaled = scaler.transform(df_client[numeric_cols])
    scaled_df = pd.DataFrame(scaled, columns=numeric_cols)

    # 3. Combinaison
    X_client_transformed = pd.concat([scaled_df, one_hot_df], axis=1)

    return X_client_transformed

from sklearn.metrics import silhouette_score

def comparer_silhouette(X, labels_kmeans, labels_agglom):
    """
    Compare le Silhouette Score entre KMeans et Agglomerative Clustering.

    Paramètres:
        X : ndarray ou DataFrame
            Données transformées (features utilisées pour le clustering)
        labels_kmeans : array
            Labels prédits par KMeans
        labels_agglom : array
            Labels prédits par Agglomerative Clustering

    Retourne:
        meilleur_modele : str
            "KMeans" ou "Agglomerative Clustering"
    """

    # Calcul des scores
    silhouette_kmeans = silhouette_score(X, labels_kmeans)
    silhouette_agglo = silhouette_score(X, labels_agglom)

    print(f"\n📊 Silhouette KMeans: {silhouette_kmeans:.3f}")
    print(f"📊 Silhouette Agglomerative: {silhouette_agglo:.3f}")

    # Sélection du meilleur modèle
    if silhouette_kmeans > silhouette_agglo:
        meilleur_modele = "KMeans"
        print("🎯 CONCLUSION : KMeans est le meilleur modèle (Silhouette plus élevé)")
    else:
        meilleur_modele = "Agglomerative Clustering"
        print("🎯 CONCLUSION : Agglomerative Clustering est le meilleur modèle (Silhouette plus élevé)")

    return meilleur_modele
meilleur = comparer_silhouette(X_transformed, df_assurance['cluster'], df_assurance['cluster_hier'])

"""#Objectif DS: Construire les 2 modèles de régression pour prédire les frais médicaux (charges) et comparer deux modèles : Régression Linéaire vs XGBoost"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
from typing import Tuple, Dict, Any

#Pour de meilleurs visuels
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print(X_transformed.head())

X = X_transformed
y = df_assurance["charges"]
print("Dimensions de X :", X.shape)
print("Dimensions de y :", y.shape)

# Split Train/Test (une seule fois pour les deux modèles)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Taille du jeu d’entraînement :", X_train.shape)
print("Taille du jeu de test :", X_test.shape)

"""
*   Fonction evaluate_model va évaluer un modèle et retourne les métriques

*   Visualisation les prédictions vs valeurs réelles

*   Création d'un DataFrame de comparaison à partir d'un dictionnaire de métriques"""

def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray, model_name: str) -> Dict[str, float]:
    """
    Évalue un modèle et retourne les métriques
    """
    metrics = {
        'MAE': mean_absolute_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'R2': r2_score(y_true, y_pred),
        'MAPE': np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # Erreur en pourcentage
    }

    print(f"\n📊 Évaluation {model_name} :")
    for metric, value in metrics.items():
        if metric == 'MAPE':
            print(f"{metric:5} : {value:.2f}%")
        else:
            print(f"{metric:5} : {value:.2f}")

    return metrics

def plot_predictions(y_true: np.ndarray, y_pred: np.ndarray, model_name: str):
    """
    Visualise les prédictions vs valeurs réelles
    """
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Graphique de dispersion
    axes[0].scatter(y_true, y_pred, alpha=0.6, s=50)
    axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
    axes[0].set_xlabel("Charges réelles")
    axes[0].set_ylabel("Charges prédites")
    axes[0].set_title(f"{model_name} : Prédictions vs Réelles")
    axes[0].grid(True, alpha=0.3)

    # Distribution des erreurs
    errors = y_true - y_pred
    sns.histplot(errors, kde=True, ax=axes[1])
    axes[1].axvline(x=0, color='r', linestyle='--')
    axes[1].set_title(f"{model_name} : Distribution des erreurs")
    axes[1].set_xlabel("Erreur de prédiction")

    plt.tight_layout()
    plt.show()

    return errors

def create_comparison_df(metrics_dict: Dict[str, Dict]) -> pd.DataFrame:
    """
    Crée un DataFrame de comparaison à partir d'un dictionnaire de métriques
    """
    comparison_data = []
    for model_name, metrics in metrics_dict.items():
        row = {'Modèle': model_name}
        row.update(metrics)
        comparison_data.append(row)

    return pd.DataFrame(comparison_data)

"""# Modèle 1 : Régression Linéaire

"""

# Modèle 1 : Régression Linéaire

print("🔧 Entraînement du modèle de Régression Linéaire...")

# Construction et entraînement du modèle
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)

# Prédictions
y_pred_lr = model_lr.predict(X_test)

# Évaluation avec la fonction
metrics_lr = evaluate_model(y_test, y_pred_lr, "Régression Linéaire")

# Visualisations
errors_lr = plot_predictions(y_test, y_pred_lr, "Régression Linéaire")

# Informations supplémentaires
print(f"\n📈 Coefficients du modèle linéaire : {len(model_lr.coef_)}")
print(f"📍 Intercept : {model_lr.intercept_:.2f}")

"""#Modèle 2 : XGBoost

"""

#Modèle 2 : XGBoost

print("\n🔧 Entraînement du modèle XGBoost...")

# Conversion en DMatrix
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Paramètres avec validation croisée implicite
params = {
    "objective": "reg:squarederror",
    "tree_method": "hist",
    "learning_rate": 0.1,
    "max_depth": 6,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "reg_alpha": 0.1,  # L1 regularization
    "reg_lambda": 1.0, # L2 regularization
    "seed": 42
}

# Entraînement avec callback de progression
evals = [(dtrain, "train"), (dtest, "validation")]

print("⏳ Début de l'entraînement XGBoost...")
model_xgb = xgb.train(
    params=params,
    dtrain=dtrain,
    num_boost_round=1000,
    evals=evals,
    early_stopping_rounds=50,
    verbose_eval=50
)

# Prédictions
y_pred_xgb = model_xgb.predict(dtest)

# Évaluation
metrics_xgb = evaluate_model(y_test, y_pred_xgb, "XGBoost")

# Visualisations
errors_xgb = plot_predictions(y_test, y_pred_xgb, "XGBoost")

# Feature importance
plt.figure(figsize=(3, 8))
xgb.plot_importance(model_xgb, max_num_features=15, importance_type='weight')
plt.title("XGBoost - Importance des caractéristiques")
plt.tight_layout()
plt.show()

"""# Comparaison des 2 algorithmes

"""

# Création du DataFrame de comparaison
metrics_dict = {
    "Régression Linéaire": metrics_lr,
    "XGBoost": metrics_xgb
}

results_df = create_comparison_df(metrics_dict)

print("\n" + "="*50)
print("📊 RÉSULTATS COMPARATIFS DÉTAILLÉS")
print("="*50)
print(results_df.round(4))

# Visualisation comparative améliorée
fig, axes = plt.subplots(2, 2, figsize=(8, 8))

# Graphique des métriques
metrics_to_plot = ['MAE', 'RMSE', 'R2', 'MAPE']
for idx, metric in enumerate(metrics_to_plot):
    ax = axes[idx//2, idx%2]
    sns.barplot(data=results_df, x='Modèle', y=metric, ax=ax, palette='viridis')
    ax.set_title(f'Comparaison - {metric}')
    ax.tick_params(axis='x', rotation=45)

    # Ajout des valeurs sur les barres
    for container in ax.containers:
        ax.bar_label(container, fmt='%.3f')

plt.tight_layout()
plt.show()

# Graphique des erreurs résiduelles
plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
sns.boxplot(data=[errors_lr, errors_xgb], palette='Set2')
plt.xticks([0, 1], ['Régression Linéaire', 'XGBoost'])
plt.title('Distribution des erreurs résiduelles')
plt.ylabel('Erreur')

plt.subplot(1, 2, 2)
sns.kdeplot(errors_lr, label='Régression Linéaire', fill=True)
sns.kdeplot(errors_xgb, label='XGBoost', fill=True)
plt.axvline(x=0, color='red', linestyle='--', alpha=0.5)
plt.title('Densité des erreurs')
plt.xlabel('Erreur')
plt.legend()

plt.tight_layout()
plt.show()

"""#Analyse de performance supplémentaire entre les 2 algorithmes

"""

#Analyse de performance supplémentaire

def analyze_residuals(y_true: np.ndarray, y_pred: np.ndarray, model_name: str):
    """Analyse approfondie des résidus"""
    residuals = y_true - y_pred

    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    # Résidus vs prédictions
    axes[0,0].scatter(y_pred, residuals, alpha=0.6)
    axes[0,0].axhline(y=0, color='red', linestyle='--')
    axes[0,0].set_xlabel('Prédictions')
    axes[0,0].set_ylabel('Résidus')
    axes[0,0].set_title(f'{model_name} - Résidus vs Prédictions')

    # QQ plot pour normalité
    from scipy import stats
    stats.probplot(residuals, dist="norm", plot=axes[0,1])
    axes[0,1].set_title(f'{model_name} - QQ Plot')

    # Autocorrélation des résidus
    from statsmodels.tsa.stattools import acf
    acf_residuals = acf(residuals, nlags=40)
    axes[1,0].stem(acf_residuals)
    axes[1,0].set_title(f'{model_name} - Autocorrélation des résidus')
    axes[1,0].set_xlabel('Lag')
    axes[1,0].set_ylabel('Autocorrélation')

    # Histogramme des résidus
    axes[1,1].hist(residuals, bins=30, density=True, alpha=0.7)
    axes[1,1].set_xlabel('Résidus')
    axes[1,1].set_ylabel('Densité')
    axes[1,1].set_title(f'{model_name} - Distribution des résidus')

    plt.tight_layout()
    plt.show()

# Application aux deux modèles
analyze_residuals(y_test, y_pred_lr, "Régression Linéaire")
analyze_residuals(y_test, y_pred_xgb, "XGBoost")

"""# Identification du meilleur modèle

"""

# Identification du meilleur modèle

# Access metrics from the dictionaries
mae_xgb = metrics_xgb['MAE']
mae_lr = metrics_lr['MAE']
r2_xgb = metrics_xgb['R2']
r2_lr = metrics_lr['R2']


if mae_xgb < mae_lr and r2_xgb > r2_lr:
    meilleur_modele = "XGBoost"
    modele_final = model_xgb
    print("🎯 CONCLUSION : XGBoest est sélectionné comme modèle final")
    print("   ✓ Plus faible MAE (erreur moyenne)")
    print("   ✓ Meilleur R² (explication de la variance)")
else:
    meilleur_modele = "Régression Linéaire"
    modele_final = model_lr
    print("🎯 CONCLUSION : Régression Linéaire est sélectionnée comme modèle final")

print(f"📊 Amélioration du MAE : {((mae_lr - mae_xgb) / mae_lr * 100):.1f}%")
print(f"📊 Amélioration du R² : {((r2_xgb - r2_lr) / r2_lr * 100):.1f}%")

"""#  PRÉDICTION SUR DE NOUVEAUX CLIENTS

"""

#  PRÉDICTION SUR DE NOUVEAUX CLIENTS

# 1. NOUVEAUX CLIENTS
nouveaux_clients = pd.DataFrame({
    'age': [25, 45, 60, 19, 35],
    'bmi': [22.5, 28.9, 33.1, 19.2, 26.5],
    'children': [0, 2, 1, 0, 2],
    'sex_female': [0, 1, 0, 1, 0],
    'sex_male': [1, 0, 1, 0, 1],
    'smoker_no': [1, 0, 0, 1, 1],
    'smoker_yes': [0, 1, 1, 0, 0],
    'region_northeast': [0, 1, 0, 0, 0],
    'region_northwest': [0, 0, 0, 1, 0],
    'region_southeast': [0, 0, 1, 0, 0],
    'region_southwest': [1, 0, 0, 0, 1]
})

print("👥 PROFILS DES NOUVEAUX CLIENTS :")
print(nouveaux_clients[['age', 'bmi', 'children', 'sex_male', 'smoker_yes']])

# 2. PRÉDICTION AVEC LE MEILLEUR MODÈLE
predictions = modele_final.predict(xgb.DMatrix(nouveaux_clients))
nouveaux_clients['frais_predits'] = predictions

# 3. ANALYSE DES RÉSULTATS (NOUVEAU)
print("\n" + "="*60)
print("💰 RÉSULTATS DES PRÉDICTIONS - ANALYSE DÉTAILLÉE")
print("="*60)

for i in range(len(nouveaux_clients)):
    client = nouveaux_clients.iloc[i]

    # Catégorisation du risque
    if client['smoker_yes'] == 1:
        risque = "🔴 RISQUE ÉLEVÉ"
        motif = "(Fumeur)"
    elif client['bmi'] > 30:
        risque = "🟡 RISQUE MODÉRÉ"
        motif = "(Obésité)"
    elif client['age'] > 50:
        risque = "🟠 RISQUE MOYEN"
        motif = "(Âge avancé)"
    else:
        risque = "🟢 RISQUE FAIBLE"
        motif = "(Profil sain)"

    print(f"👤 Client {i+1}:")
    print(f"   • 📊 Profil: {client['age']} ans, BMI {client['bmi']}, {client['children']} enfant(s)")
    print(f"   • 🚬 Fumeur: {'Oui' if client['smoker_yes'] == 1 else 'Non'}")
    print(f"   • 💰 Frais prédits: ${client['frais_predits']:,.2f}")
    print(f"   • ⚠️  Niveau de risque: {risque} {motif}")
    print("-" * 50)

# 4. STATISTIQUES GLOBALES (NOUVEAU)
print("\n📈 STATISTIQUES GLOBALES DES PRÉDICTIONS :")
print(f"• 📊 Frais moyen: ${nouveaux_clients['frais_predits'].mean():,.2f}")
print(f"• 📉 Frais minimum: ${nouveaux_clients['frais_predits'].min():,.2f}")
print(f"• 📈 Frais maximum: ${nouveaux_clients['frais_predits'].max():,.2f}")
print(f"• 🔄 Écart type: ${nouveaux_clients['frais_predits'].std():,.2f}")

# 5. VISUALISATION DES PRÉDICTIONS (NOUVEAU)
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
colors = ['red' if x == 1 else 'green' for x in nouveaux_clients['smoker_yes']]
plt.bar([f'Client {i+1}' for i in range(len(nouveaux_clients))],
        nouveaux_clients['frais_predits'], color=colors, alpha=0.7)
plt.title('Frais médicaux prédits par client\n(Rouge=Fumeur, Vert=Non-fumeur)')
plt.xticks(rotation=45)
plt.ylabel('Frais ($)')

plt.subplot(1, 2, 2)
plt.scatter(nouveaux_clients['age'], nouveaux_clients['frais_predits'],
           c=nouveaux_clients['bmi'], s=100, cmap='viridis')
plt.colorbar(label='BMI')
plt.xlabel('Âge')
plt.ylabel('Frais prédits ($)')
plt.title('Impact de l\'âge et du BMI')

plt.tight_layout()
plt.show()

"""# Application Dash"""

# =============================================================================
# APPLICATION DASH OPTIMISÉE - VERSION FINALE AVEC LIEN COLAB
# =============================================================================




"""**Classification**

*KNN*
"""

quantiles = df_assurance['charges'].quantile([0.33, 0.66]).values

def assign_reimbursement_class(charges):
    if charges <= quantiles[0]:
        return "R3"  # Faible charges → fort remboursement
    elif charges <= quantiles[1]:
        return "R2"  # Charges moyennes → remboursement moyen
    else:
        return "R1"  # Charges élevées → faible remboursement

df_assurance['remboursement_class'] = df_assurance['charges'].apply(assign_reimbursement_class)

print("Répartition des classes :")
print(df_assurance['remboursement_class'].value_counts())

X = X_transformed.values  # tes features déjà encodées + normalisées
y = df_assurance['remboursement_class'].values  # ta cible

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

knn = KNeighborsClassifier(n_neighbors=5)

knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

print("Rapport de classification (KNN k=5):\n")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred, labels=["R1","R2","R3"])
ConfusionMatrixDisplay(cm, display_labels=["R1","R2","R3"]).plot(cmap=plt.cm.Blues)
plt.title("Matrice de confusion - KNN (k=5)")
plt.show()

# 5) (Optionnel) Chercher le meilleur k
scores = []
ks = range(1, 21)
for k in ks:
    m = KNeighborsClassifier(n_neighbors=k)
    m.fit(X_train, y_train)
    scores.append(m.score(X_test, y_test))

plt.figure()
plt.plot(ks, scores, marker='o')
plt.xlabel("Nombre de voisins (k)")
plt.ylabel("Accuracy sur test")
plt.title("Choix du meilleur k (avec X_transformed)")
plt.show()

"""Arbre

"""

X = X_transformed   # Ton jeu de données encodé et normalisé
y = df_assurance["remboursement_class"]

# Vérifier les dimensions
X.shape, y.shape

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# --- 3. Entraîner l’arbre de décision
clf = DecisionTreeClassifier(
    max_depth=5,
    class_weight={'R1':1, 'R2':1, 'R3':1.5}, # pondération des classes
    random_state=42
)
clf.fit(X_train, y_train)

# Prédictions
y_pred = clf.predict(X_test)

# Matrice de confusion
print("Matrice de confusion :\n", confusion_matrix(y_test, y_pred))

# Rapport de classification
print("\nRapport de classification :\n", classification_report(y_test, y_pred))

ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, cmap='Blues')
plt.show()

import seaborn as sns
from sklearn.metrics import classification_report

report = classification_report(y_test, y_pred, output_dict=True)
df_report = pd.DataFrame(report).iloc[:-1, :3]  # exclut accuracy

sns.heatmap(df_report, annot=True, cmap="Blues")
plt.title("Precision / Recall / F1-score")
plt.show()

encoded_cols = encoder.get_feature_names_out(categorical_cols)
all_features = numeric_cols + list(encoded_cols)

plt.figure(figsize=(20,10))
plot_tree(clf, feature_names=all_features, class_names=['R1','R2','R3'], filled=True)
plt.show()


#afficahge 

# =============================================================================
# SAUVEGARDE DES MODÈLES POUR FLASK
# =============================================================================

# Sauvegarde des modèles
import joblib
import os
os.makedirs('models', exist_ok=True)
joblib.dump(modele_final, 'models/modele_final.pkl')
joblib.dump(encoder, 'models/encoder.pkl')
joblib.dump(scaler, 'models/scaler.pkl')
joblib.dump(clf, 'models/clf.pkl')
print("✅ Modèles sauvegardés!")


###

# =============================================================================
# SAUVEGARDE DES MODÈLES POUR FLASK
# =============================================================================

def sauvegarder_modeles():
    """Sauvegarde tous les modèles nécessaires pour l'application Flask"""
    import joblib
    import os
    
    # Créer le dossier models s'il n'existe pas
    os.makedirs('models', exist_ok=True)
    
    try:
        # Vérifier que les modèles existent
        required_models = {
            'modele_final': modele_final,
            'encoder': encoder,
            'scaler': scaler,
            'clf': clf
        }
        
        for name, model in required_models.items():
            if model is None:
                print(f"❌ Le modèle {name} n'est pas défini")
                return False
        
        # Sauvegarder les modèles et transformateurs
        joblib.dump(modele_final, 'models/modele_final.pkl')
        joblib.dump(encoder, 'models/encoder.pkl')
        joblib.dump(scaler, 'models/scaler.pkl')
        joblib.dump(clf, 'models/clf.pkl')
        
        print("✅ Modèles sauvegardés avec succès dans le dossier 'models/'")
        print("📁 Fichiers créés :")
        print("   - modele_final.pkl")
        print("   - encoder.pkl") 
        print("   - scaler.pkl")
        print("   - clf.pkl")
        return True
        
    except Exception as e:
        print(f"❌ Erreur lors de la sauvegarde : {e}")
        return False

# Exécuter la sauvegarde si ce script est exécuté directement
if __name__ == "__main__":
    # Attendre que tous les modèles soient créés dans votre code principal
    # Cette partie doit être appelée après l'entraînement de tous les modèles
    
    # Pour l'instant, exécutons juste le nettoyage et l'analyse
    print("🔍 Analyse des données terminée!")
    
    # Si vous voulez sauvegarder immédiatement, décommentez la ligne suivante :
    # sauvegarder_modeles()